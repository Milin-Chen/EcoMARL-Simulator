"""
æµ‹è¯•ç»Ÿä¸€è®­ç»ƒè„šæœ¬
Test Unified Training Script

éªŒè¯:
1. TrainingConfigæ­£ç¡®åŠ è½½
2. HPOå¥–åŠ±å‡½æ•°åŒ…å«æŒç»­è¿½å‡»/é€ƒè·‘åŠ æˆ
3. æ ‡å‡†æ¨¡å¼å’ŒHPOæ¨¡å¼éƒ½èƒ½æ­£å¸¸åˆ›å»ºç¯å¢ƒ
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from config import TrainingConfig, AgentConfig, EnvConfig
from rl_env import (
    EnhancedEcoMARLEnv,
    CurriculumEcoMARLEnv,
    CurriculumEcoMARLEnvHPO,
    Stage1HunterRewardHPO,
    Stage3PreyRewardHPO,
)


def test_training_config():
    """æµ‹è¯•TrainingConfigåŠ è½½"""
    print("\n=== æµ‹è¯•1: TrainingConfigåŠ è½½ ===")

    config = TrainingConfig()
    print(f"âœ“ PPOå‚æ•°:")
    print(f"  - n_steps: {config.PPO_N_STEPS}")
    print(f"  - batch_size: {config.PPO_BATCH_SIZE}")
    print(f"  - learning_rateé»˜è®¤: è§å„é˜¶æ®µé…ç½®")

    stages = config.get_stage_configs()
    print(f"\nâœ“ è¯¾ç¨‹å­¦ä¹ é˜¶æ®µ: {list(stages.keys())}")

    for stage_name, stage_config in stages.items():
        print(f"\n  {stage_name}:")
        print(f"    - åç§°: {stage_config.name}")
        print(f"    - è®­ç»ƒæ­¥æ•°: {stage_config.total_timesteps}")
        print(f"    - å­¦ä¹ ç‡: {stage_config.learning_rate}")
        print(f"    - çŒäººæ•°: {stage_config.n_hunters}")
        print(f"    - çŒç‰©æ•°: {stage_config.n_prey}")

    print("\nâœ… TrainingConfigæµ‹è¯•é€šè¿‡")


def test_hpo_rewards_have_chase_streak():
    """æµ‹è¯•HPOå¥–åŠ±å‡½æ•°æ˜¯å¦åŒ…å«æŒç»­è¿½å‡»/é€ƒè·‘åŠ æˆ"""
    print("\n=== æµ‹è¯•2: HPOå¥–åŠ±å‡½æ•°å®Œæ•´æ€§ ===")

    # æµ‹è¯•Stage1HunterRewardHPO
    hunter_reward = Stage1HunterRewardHPO(total_steps=50000, enable_hpo=True)

    assert hasattr(hunter_reward, 'chase_streak'), "âŒ Stage1HunterRewardHPOç¼ºå°‘chase_streakå±æ€§"
    assert hasattr(hunter_reward, 'max_chase_multiplier'), "âŒ Stage1HunterRewardHPOç¼ºå°‘max_chase_multiplierå±æ€§"
    assert hasattr(hunter_reward, 'chase_buildup_steps'), "âŒ Stage1HunterRewardHPOç¼ºå°‘chase_buildup_stepså±æ€§"
    assert hasattr(hunter_reward, 'hpo_enhancer'), "âŒ Stage1HunterRewardHPOç¼ºå°‘hpo_enhancerå±æ€§"

    print(f"âœ“ Stage1HunterRewardHPO åŒ…å«:")
    print(f"  - chase_streak: {hunter_reward.chase_streak}")
    print(f"  - max_chase_multiplier: {hunter_reward.max_chase_multiplier}")
    print(f"  - chase_buildup_steps: {hunter_reward.chase_buildup_steps}")
    print(f"  - hpo_enhancer: {hunter_reward.hpo_enhancer is not None}")

    # æµ‹è¯•Stage3PreyRewardHPO
    prey_reward = Stage3PreyRewardHPO(total_steps=50000, enable_hpo=True)

    assert hasattr(prey_reward, 'escape_streak'), "âŒ Stage3PreyRewardHPOç¼ºå°‘escape_streakå±æ€§"
    assert hasattr(prey_reward, 'max_escape_multiplier'), "âŒ Stage3PreyRewardHPOç¼ºå°‘max_escape_multiplierå±æ€§"
    assert hasattr(prey_reward, 'escape_buildup_steps'), "âŒ Stage3PreyRewardHPOç¼ºå°‘escape_buildup_stepså±æ€§"
    assert hasattr(prey_reward, 'hpo_enhancer'), "âŒ Stage3PreyRewardHPOç¼ºå°‘hpo_enhancerå±æ€§"

    print(f"\nâœ“ Stage3PreyRewardHPO åŒ…å«:")
    print(f"  - escape_streak: {prey_reward.escape_streak}")
    print(f"  - max_escape_multiplier: {prey_reward.max_escape_multiplier}")
    print(f"  - escape_buildup_steps: {prey_reward.escape_buildup_steps}")
    print(f"  - hpo_enhancer: {prey_reward.hpo_enhancer is not None}")

    print("\nâœ… HPOå¥–åŠ±å‡½æ•°å®Œæ•´æ€§æµ‹è¯•é€šè¿‡")


def test_standard_env_creation():
    """æµ‹è¯•æ ‡å‡†ç¯å¢ƒåˆ›å»º"""
    print("\n=== æµ‹è¯•3: æ ‡å‡†ç¯å¢ƒåˆ›å»º ===")

    agent_config = AgentConfig()
    env_config = EnvConfig()

    stage_config = TrainingConfig.get_stage_config("stage1")

    base_env = EnhancedEcoMARLEnv(
        agent_config=agent_config,
        env_config=env_config,
        n_hunters=stage_config.n_hunters,
        n_prey=stage_config.n_prey,
        max_steps=1000,
        use_v2_rewards=True,
    )

    env = CurriculumEcoMARLEnv(
        base_env=base_env,
        stage="stage1",
    )

    print(f"âœ“ åˆ›å»ºæ ‡å‡†ç¯å¢ƒæˆåŠŸ")
    print(f"  - è§‚å¯Ÿç©ºé—´: {env.observation_space.shape}")
    print(f"  - åŠ¨ä½œç©ºé—´: {env.action_space.shape}")
    print(f"  - é˜¶æ®µ: stage1")

    # æµ‹è¯•é‡ç½®
    obs, info = env.reset()
    print(f"  - é‡ç½®æˆåŠŸ, è§‚å¯Ÿç»´åº¦: {obs.shape}")

    env.close()
    print("âœ… æ ‡å‡†ç¯å¢ƒåˆ›å»ºæµ‹è¯•é€šè¿‡")


def test_hpo_env_creation():
    """æµ‹è¯•HPOç¯å¢ƒåˆ›å»º"""
    print("\n=== æµ‹è¯•4: HPOç¯å¢ƒåˆ›å»º ===")

    agent_config = AgentConfig()
    env_config = EnvConfig()

    stage_config = TrainingConfig.get_stage_config("stage1")

    base_env = EnhancedEcoMARLEnv(
        agent_config=agent_config,
        env_config=env_config,
        n_hunters=stage_config.n_hunters,
        n_prey=stage_config.n_prey,
        max_steps=1000,
        use_v2_rewards=True,
    )

    env = CurriculumEcoMARLEnvHPO(
        base_env=base_env,
        stage="stage1",
        enable_hpo=True,
        total_steps=stage_config.total_timesteps,
    )

    print(f"âœ“ åˆ›å»ºHPOç¯å¢ƒæˆåŠŸ")
    print(f"  - è§‚å¯Ÿç©ºé—´: {env.observation_space.shape}")
    print(f"  - åŠ¨ä½œç©ºé—´: {env.action_space.shape}")
    print(f"  - é˜¶æ®µ: stage1")
    print(f"  - HPOå¯ç”¨: {env.enable_hpo}")

    # æµ‹è¯•é‡ç½®
    obs, info = env.reset()
    print(f"  - é‡ç½®æˆåŠŸ, è§‚å¯Ÿç»´åº¦: {obs.shape}")

    # æ£€æŸ¥HPOå¢å¼ºå™¨
    if hasattr(env, 'hpo_enhancer') and env.hpo_enhancer:
        stats = env.get_hpo_stats()
        print(f"  - HPOç»Ÿè®¡: {stats is not None}")

    env.close()
    print("âœ… HPOç¯å¢ƒåˆ›å»ºæµ‹è¯•é€šè¿‡")


def test_agent_config_parameters():
    """æµ‹è¯•AgentConfigå‚æ•°ä¸€è‡´æ€§"""
    print("\n=== æµ‹è¯•5: AgentConfigå‚æ•°ä¸€è‡´æ€§ ===")

    config = AgentConfig()

    # éªŒè¯å…³é”®å‚æ•°
    expected_params = {
        'HUNTER_SPEED_MAX': 50.0,
        'HUNTER_ANGULAR_VELOCITY_MAX': 0.15,
        'PREY_SPEED_MAX': 45.0,
        'PREY_ANGULAR_VELOCITY_MAX': 0.18,
    }

    all_pass = True
    for param, expected_value in expected_params.items():
        actual_value = getattr(config, param)
        if actual_value == expected_value:
            print(f"  âœ“ {param}: {actual_value}")
        else:
            print(f"  âŒ {param}: æœŸæœ›{expected_value}, å®é™…{actual_value}")
            all_pass = False

    if all_pass:
        print("âœ… AgentConfigå‚æ•°ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
    else:
        print("âŒ AgentConfigå‚æ•°ä¸€è‡´æ€§æµ‹è¯•å¤±è´¥")
        raise AssertionError("AgentConfigå‚æ•°ä¸ä¸€è‡´")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 80)
    print("ç»Ÿä¸€è®­ç»ƒè„šæœ¬æµ‹è¯•å¥—ä»¶")
    print("=" * 80)

    try:
        test_training_config()
        test_hpo_rewards_have_chase_streak()
        test_standard_env_creation()
        test_hpo_env_creation()
        test_agent_config_parameters()

        print("\n" + "=" * 80)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("=" * 80)
        print("\nå¯ä»¥å®‰å…¨ä½¿ç”¨æ–°çš„train_curriculum.py:")
        print("  python train_curriculum.py --stage stage1          # æ ‡å‡†æ¨¡å¼")
        print("  python train_curriculum.py --stage stage1 --enable_hpo  # HPOæ¨¡å¼")
        print()

    except Exception as e:
        print("\n" + "=" * 80)
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print("=" * 80)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
