"""
æµ‹è¯•å¢å¼ºç‰ˆå¥–åŠ±å‡½æ•° - å¿«é€ŸéªŒè¯
æ£€æŸ¥:
1. å¥–åŠ±æ˜¯å¦éé›¶
2. æ•é£Ÿäº‹ä»¶æ˜¯å¦å‘ç”Ÿ
3. è¿½å‡»è¡Œä¸ºæ˜¯å¦æœ‰å¥–åŠ±
4. åŸåœ°è½¬åœˆæ˜¯å¦è¢«æƒ©ç½š
"""

import numpy as np
from rl_env import EnhancedEcoMARLEnv


def test_enhanced_rewards():
    """æµ‹è¯•å¢å¼ºç‰ˆå¥–åŠ±å‡½æ•°"""
    print("=" * 70)
    print("æµ‹è¯•å¢å¼ºç‰ˆå¥–åŠ±å‡½æ•°")
    print("=" * 70)

    # åˆ›å»ºç¯å¢ƒ
    env = EnhancedEcoMARLEnv(
        n_hunters=3,
        n_prey=6,
        max_steps=500,
    )

    print("\nâœ“ ç¯å¢ƒåˆ›å»ºæˆåŠŸ")
    print(f"  çŒäººæ•°é‡: {env.n_hunters}")
    print(f"  çŒç‰©æ•°é‡: {env.n_prey}")

    # é‡ç½®ç¯å¢ƒ
    obs = env.reset()
    print("\nâœ“ ç¯å¢ƒé‡ç½®æˆåŠŸ")
    print(f"  è§‚å¯Ÿæ•°é‡: {len(obs)} agents")

    # è¿è¡Œæµ‹è¯•
    print("\n" + "=" * 70)
    print("å¼€å§‹æµ‹è¯• (è¿è¡Œ100æ­¥)")
    print("=" * 70)

    total_hunter_reward = 0.0
    total_prey_reward = 0.0
    non_zero_steps = 0
    predation_count = 0
    reward_breakdown = {
        "positive_hunter": 0,
        "negative_hunter": 0,
        "positive_prey": 0,
        "negative_prey": 0,
    }

    for step in range(100):
        # éšæœºåŠ¨ä½œ - ä¸ºæ¯ä¸ªagentç”ŸæˆåŠ¨ä½œ
        actions = {}
        for agent_id in obs.keys():
            actions[agent_id] = np.random.randn(2) * 0.5

        # æ‰§è¡Œæ­¥éª¤
        obs, rewards, dones, info = env.step(actions)

        # ç»Ÿè®¡å¥–åŠ± - æŒ‰ç±»å‹åˆ†ç»„ (h_å¼€å¤´æ˜¯hunter, p_å¼€å¤´æ˜¯prey)
        hunter_reward = sum(r for aid, r in rewards.items() if aid.startswith('h_'))
        prey_reward = sum(r for aid, r in rewards.items() if aid.startswith('p_'))

        total_hunter_reward += hunter_reward
        total_prey_reward += prey_reward

        if abs(hunter_reward) > 0.01 or abs(prey_reward) > 0.01:
            non_zero_steps += 1

        # ç»Ÿè®¡æ­£è´Ÿå¥–åŠ±
        if hunter_reward > 0:
            reward_breakdown["positive_hunter"] += 1
        elif hunter_reward < 0:
            reward_breakdown["negative_hunter"] += 1

        if prey_reward > 0:
            reward_breakdown["positive_prey"] += 1
        elif prey_reward < 0:
            reward_breakdown["negative_prey"] += 1

        # æ£€æŸ¥æ•é£Ÿäº‹ä»¶
        new_predation_count = info["episode_stats"]["total_predations"]
        if new_predation_count > predation_count:
            predation_count = new_predation_count
            print(f"\nğŸ¯ æ­¥éª¤ {step}: æ•é£Ÿäº‹ä»¶å‘ç”Ÿ! æ€»æ•é£Ÿæ•°: {predation_count}")
            print(f"   çŒäººå¥–åŠ±: {hunter_reward:.2f}")
            print(f"   å½“å‰çŒäººæ•°: {info['population']['hunters']}, çŒç‰©æ•°: {info['population']['preys']}")

        # æ¯20æ­¥è¾“å‡ºä¸€æ¬¡
        if (step + 1) % 20 == 0:
            print(f"\næ­¥éª¤ {step+1}/100:")
            print(f"  çŒäººå¥–åŠ±: {hunter_reward:.3f} (ç´¯è®¡: {total_hunter_reward:.2f})")
            print(f"  çŒç‰©å¥–åŠ±: {prey_reward:.3f} (ç´¯è®¡: {total_prey_reward:.2f})")
            print(f"  éé›¶å¥–åŠ±æ­¥æ•°: {non_zero_steps}/{step+1}")
            print(f"  çŒäººæ•°: {info['population']['hunters']}, çŒç‰©æ•°: {info['population']['preys']}")

        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰agentéƒ½done
        if all(dones.values()):
            print(f"\nâš ï¸  Episodeåœ¨æ­¥éª¤ {step+1} ç»ˆæ­¢")
            break

    # æµ‹è¯•æ€»ç»“
    print("\n" + "=" * 70)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 70)

    print(f"\nğŸ“Š å¥–åŠ±ç»Ÿè®¡:")
    print(f"  æ€»çŒäººå¥–åŠ±: {total_hunter_reward:.2f}")
    print(f"  æ€»çŒç‰©å¥–åŠ±: {total_prey_reward:.2f}")
    print(f"  å¹³å‡çŒäººå¥–åŠ±/æ­¥: {total_hunter_reward / (step+1):.3f}")
    print(f"  å¹³å‡çŒç‰©å¥–åŠ±/æ­¥: {total_prey_reward / (step+1):.3f}")
    print(f"  éé›¶å¥–åŠ±æ­¥æ•°: {non_zero_steps}/{step+1} ({non_zero_steps/(step+1)*100:.1f}%)")

    print(f"\nğŸ“ˆ å¥–åŠ±åˆ†å¸ƒ:")
    print(f"  çŒäººæ­£å¥–åŠ±æ­¥æ•°: {reward_breakdown['positive_hunter']}")
    print(f"  çŒäººè´Ÿå¥–åŠ±æ­¥æ•°: {reward_breakdown['negative_hunter']}")
    print(f"  çŒç‰©æ­£å¥–åŠ±æ­¥æ•°: {reward_breakdown['positive_prey']}")
    print(f"  çŒç‰©è´Ÿå¥–åŠ±æ­¥æ•°: {reward_breakdown['negative_prey']}")

    print(f"\nğŸ¯ æ•é£Ÿç»Ÿè®¡:")
    print(f"  æ•é£Ÿäº‹ä»¶æ•°: {predation_count}")

    # Episodeæ€»ç»“
    summary = env.get_episode_summary()
    print(f"\nğŸ“‹ Episodeæ€»ç»“:")
    print(f"  æ€»æ­¥æ•°: {summary['steps']}")
    print(f"  æœ€ç»ˆçŒäººæ•°: {summary['final_population']['hunters']}")
    print(f"  æœ€ç»ˆçŒç‰©æ•°: {summary['final_population']['preys']}")
    print(f"  æ€»æ•é£Ÿæ•°: {summary['total_predations']}")

    # éªŒè¯ç»“æœ
    print("\n" + "=" * 70)
    print("éªŒè¯ç»“æœ")
    print("=" * 70)

    passed = []
    failed = []

    # æ£€æŸ¥1: å¥–åŠ±éé›¶
    if non_zero_steps > 10:
        passed.append("âœ“ å¥–åŠ±éé›¶ (éé›¶æ­¥æ•° > 10)")
    else:
        failed.append("âœ— å¥–åŠ±å‡ ä¹å…¨ä¸º0")

    # æ£€æŸ¥2: å¥–åŠ±åˆç†èŒƒå›´
    if -1000 < total_hunter_reward < 1000:
        passed.append("âœ“ çŒäººå¥–åŠ±åœ¨åˆç†èŒƒå›´")
    else:
        failed.append(f"âœ— çŒäººå¥–åŠ±å¼‚å¸¸: {total_hunter_reward:.2f}")

    if -1000 < total_prey_reward < 1000:
        passed.append("âœ“ çŒç‰©å¥–åŠ±åœ¨åˆç†èŒƒå›´")
    else:
        failed.append(f"âœ— çŒç‰©å¥–åŠ±å¼‚å¸¸: {total_prey_reward:.2f}")

    # æ£€æŸ¥3: å¥–åŠ±æœ‰æ­£æœ‰è´Ÿ
    if reward_breakdown["positive_hunter"] > 0 and reward_breakdown["negative_hunter"] > 0:
        passed.append("âœ“ çŒäººå¥–åŠ±æœ‰æ­£æœ‰è´Ÿ")
    else:
        failed.append("âœ— çŒäººå¥–åŠ±ç¼ºä¹å¤šæ ·æ€§")

    if reward_breakdown["positive_prey"] > 0 and reward_breakdown["negative_prey"] > 0:
        passed.append("âœ“ çŒç‰©å¥–åŠ±æœ‰æ­£æœ‰è´Ÿ")
    else:
        failed.append("âœ— çŒç‰©å¥–åŠ±ç¼ºä¹å¤šæ ·æ€§")

    # æ‰“å°ç»“æœ
    print("\né€šè¿‡çš„æ£€æŸ¥:")
    for check in passed:
        print(f"  {check}")

    if failed:
        print("\nå¤±è´¥çš„æ£€æŸ¥:")
        for check in failed:
            print(f"  {check}")
    else:
        print("\nğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡!")

    print("\n" + "=" * 70)
    print("æµ‹è¯•å®Œæˆ!")
    print("=" * 70)

    return len(failed) == 0


if __name__ == "__main__":
    success = test_enhanced_rewards()
    exit(0 if success else 1)
