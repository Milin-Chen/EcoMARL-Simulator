"""æµ‹è¯•HPOé›†æˆ"""

import sys
from pathlib import Path

PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

from rl_env import (
    HPORewardEnhancer,
)
# Import HPO components from rewards module
from rl_env.rewards.hpo_enhancements import (
    AdaptiveRewardScaling,
    AdversarialBalancer,
    DistanceProgressTracker,
)


def test_adaptive_scaling():
    """æµ‹è¯•è‡ªé€‚åº”æƒé‡ç¼©æ”¾"""
    print("=" * 80)
    print("æµ‹è¯•1: è‡ªé€‚åº”æƒé‡ç¼©æ”¾")
    print("=" * 80)

    scaler = AdaptiveRewardScaling(total_steps=45000)

    # æµ‹è¯•ä¸åŒè®­ç»ƒé˜¶æ®µ
    test_steps = [0, 11250, 22500, 33750, 45000]
    percentages = [0, 25, 50, 75, 100]

    for step, pct in zip(test_steps, percentages):
        weights = scaler.get_reward_weights(step)
        print(f"\nè¿›åº¦ {pct}% (Step {step}):")
        print(f"  ç§»åŠ¨å¥–åŠ±: {weights['movement']:.2f}")
        print(f"  è½¬å‘å¥–åŠ±: {weights['turn']:.2f}")
        print(f"  æ–¹å‘å¥–åŠ±: {weights['direction']:.2f}")
        print(f"  æ•é£Ÿå¥–åŠ±: {weights['capture']:.2f}")
        print(f"  é™æ­¢æƒ©ç½š: {weights['stationary']:.2f}")

    print("\nâœ… è‡ªé€‚åº”æƒé‡æµ‹è¯•é€šè¿‡!\n")


def test_adversarial_balancer():
    """æµ‹è¯•å¯¹æŠ—å¹³è¡¡å™¨"""
    print("=" * 80)
    print("æµ‹è¯•2: å¯¹æŠ—å¹³è¡¡å™¨")
    print("=" * 80)

    balancer = AdversarialBalancer(history_window=20)

    # æ¨¡æ‹Ÿåœºæ™¯1: çŒæ‰‹å¤ªå¼º
    print("\nåœºæ™¯1: çŒæ‰‹å¤ªå¼º (14æ¬¡æ•è·, 6æ¬¡é€ƒè„±)")
    for _ in range(14):
        balancer.update('capture')
    for _ in range(6):
        balancer.update('escape')

    stats = balancer.get_stats()
    hunter_mult, prey_mult = balancer.get_balance_multipliers()

    print(f"  çŒæ‰‹æˆåŠŸç‡: {stats['hunter_success_rate']:.2%}")
    print(f"  çŒç‰©å­˜æ´»ç‡: {stats['prey_survival_rate']:.2%}")
    print(f"  çŒæ‰‹ç³»æ•°: {hunter_mult:.2f} (åº” < 1.0)")
    print(f"  çŒç‰©ç³»æ•°: {prey_mult:.2f} (åº” > 1.0)")

    assert hunter_mult < 1.0, "çŒæ‰‹å¤ªå¼ºæ—¶åº”é™ä½çŒæ‰‹å¥–åŠ±"
    assert prey_mult > 1.0, "çŒæ‰‹å¤ªå¼ºæ—¶åº”å¢åŠ çŒç‰©å¥–åŠ±"

    # é‡ç½®
    balancer = AdversarialBalancer(history_window=20)

    # æ¨¡æ‹Ÿåœºæ™¯2: çŒç‰©å¤ªå¼º
    print("\nåœºæ™¯2: çŒç‰©å¤ªå¼º (6æ¬¡æ•è·, 14æ¬¡é€ƒè„±)")
    for _ in range(6):
        balancer.update('capture')
    for _ in range(14):
        balancer.update('escape')

    stats = balancer.get_stats()
    hunter_mult, prey_mult = balancer.get_balance_multipliers()

    print(f"  çŒæ‰‹æˆåŠŸç‡: {stats['hunter_success_rate']:.2%}")
    print(f"  çŒç‰©å­˜æ´»ç‡: {stats['prey_survival_rate']:.2%}")
    print(f"  çŒæ‰‹ç³»æ•°: {hunter_mult:.2f} (åº” > 1.0)")
    print(f"  çŒç‰©ç³»æ•°: {prey_mult:.2f} (åº” < 1.0)")

    assert hunter_mult > 1.0, "çŒç‰©å¤ªå¼ºæ—¶åº”å¢åŠ çŒæ‰‹å¥–åŠ±"
    assert prey_mult < 1.0, "çŒç‰©å¤ªå¼ºæ—¶åº”é™ä½çŒç‰©å¥–åŠ±"

    print("\nâœ… å¯¹æŠ—å¹³è¡¡å™¨æµ‹è¯•é€šè¿‡!\n")


def test_distance_tracker():
    """æµ‹è¯•è·ç¦»è¿›åº¦è¿½è¸ª"""
    print("=" * 80)
    print("æµ‹è¯•3: è·ç¦»è¿›åº¦è¿½è¸ª")
    print("=" * 80)

    tracker = DistanceProgressTracker(decay=0.99)

    # çŒæ‰‹æ¥è¿‘åœºæ™¯
    print("\nåœºæ™¯1: çŒæ‰‹æ¥è¿‘çŒç‰©")
    distances = [100.0, 90.0, 80.0, 70.0, 60.0]

    for i, dist in enumerate(distances):
        reward = tracker.compute_progress_reward(
            'hunter_1', 'hunter', dist, scale=10.0
        )
        print(f"  è·ç¦» {dist:.1f} -> å¥–åŠ±: {reward:+.2f}")

    print("\nåœºæ™¯2: çŒç‰©è¿œç¦»çŒæ‰‹")
    distances = [50.0, 60.0, 70.0, 80.0, 90.0]

    for i, dist in enumerate(distances):
        reward = tracker.compute_progress_reward(
            'prey_1', 'prey', dist, scale=10.0
        )
        print(f"  è·ç¦» {dist:.1f} -> å¥–åŠ±: {reward:+.2f}")

    print("\nâœ… è·ç¦»è¿›åº¦è¿½è¸ªæµ‹è¯•é€šè¿‡!\n")


def test_hpo_enhancer():
    """æµ‹è¯•HPOå¢å¼ºå™¨å®Œæ•´åŠŸèƒ½"""
    print("=" * 80)
    print("æµ‹è¯•4: HPOå¢å¼ºå™¨é›†æˆ")
    print("=" * 80)

    enhancer = HPORewardEnhancer(
        total_steps=45000,
        enable_adaptive=True,
        enable_balancing=True,
        enable_distance=True,
    )

    print("\nåˆå§‹çŠ¶æ€:")
    stats = enhancer.get_stats()
    print(f"  å½“å‰æ­¥æ•°: {stats['current_step']}")
    print(f"  è®­ç»ƒè¿›åº¦: {stats['progress']:.2%}")

    # æ¨¡æ‹Ÿè®­ç»ƒå¾ªç¯
    print("\næ¨¡æ‹Ÿè®­ç»ƒ...")
    for step in range(10):
        enhancer.step()

        # æ¨¡æ‹Ÿæ•é£Ÿäº‹ä»¶
        if step % 3 == 0:
            enhancer.update_outcome('capture')
        else:
            enhancer.update_outcome('escape')

        # æ¨¡æ‹Ÿè·ç¦»å¥–åŠ±
        reward = enhancer.compute_distance_progress_reward(
            'entity_1', 'hunter', 100.0 - step * 5, scale=10.0
        )

    # æ£€æŸ¥çŠ¶æ€
    stats = enhancer.get_stats()
    print(f"\n10æ­¥åçŠ¶æ€:")
    print(f"  å½“å‰æ­¥æ•°: {stats['current_step']}")
    print(f"  è®­ç»ƒè¿›åº¦: {stats['progress']:.2%}")
    print(f"  å¹³è¡¡ç»Ÿè®¡: {stats['balance']}")

    # é‡ç½®
    enhancer.reset()
    stats = enhancer.get_stats()
    print(f"\né‡ç½®åçŠ¶æ€:")
    print(f"  å½“å‰æ­¥æ•°: {stats['current_step']}")

    print("\nâœ… HPOå¢å¼ºå™¨é›†æˆæµ‹è¯•é€šè¿‡!\n")


def test_reward_functions():
    """æµ‹è¯•HPOå¥–åŠ±å‡½æ•°"""
    print("=" * 80)
    print("æµ‹è¯•5: HPOå¥–åŠ±å‡½æ•°é›†æˆ")
    print("=" * 80)

    from rl_env.rewards_curriculum_hpo import (
        Stage1HunterRewardHPO,
        Stage3PreyRewardHPO
    )

    # æµ‹è¯•çŒæ‰‹å¥–åŠ±
    print("\nåˆ›å»ºStage1çŒæ‰‹å¥–åŠ± (HPOå¯ç”¨)...")
    hunter_reward = Stage1HunterRewardHPO(
        total_steps=45000,
        enable_hpo=True
    )

    print("âœ“ Stage1HunterRewardHPO åˆ›å»ºæˆåŠŸ")
    print(f"  HPOå¯ç”¨: {hunter_reward.enable_hpo}")
    print(f"  å¢å¼ºå™¨å­˜åœ¨: {hunter_reward.hpo_enhancer is not None}")

    # æµ‹è¯•çŒç‰©å¥–åŠ±
    print("\nåˆ›å»ºStage3çŒç‰©å¥–åŠ± (HPOå¯ç”¨)...")
    prey_reward = Stage3PreyRewardHPO(
        total_steps=45000,
        enable_hpo=True
    )

    print("âœ“ Stage3PreyRewardHPO åˆ›å»ºæˆåŠŸ")
    print(f"  HPOå¯ç”¨: {prey_reward.enable_hpo}")
    print(f"  å¢å¼ºå™¨å­˜åœ¨: {prey_reward.hpo_enhancer is not None}")

    # æµ‹è¯•æƒé‡è·å–
    print("\næµ‹è¯•æƒé‡è·å–...")
    weights = hunter_reward.hpo_enhancer.get_reward_weights()
    print(f"  ç§»åŠ¨å¥–åŠ±æƒé‡: {weights['movement']:.2f}")
    print(f"  æ•é£Ÿå¥–åŠ±æƒé‡: {weights['capture']:.2f}")

    # æµ‹è¯•å¹³è¡¡ç³»æ•°
    print("\næµ‹è¯•å¹³è¡¡ç³»æ•°...")
    hunter_mult, prey_mult = hunter_reward.hpo_enhancer.get_balance_multipliers()
    print(f"  çŒæ‰‹ç³»æ•°: {hunter_mult:.2f}")
    print(f"  çŒç‰©ç³»æ•°: {prey_mult:.2f}")

    print("\nâœ… HPOå¥–åŠ±å‡½æ•°æµ‹è¯•é€šè¿‡!\n")


def test_performance():
    """æ€§èƒ½æµ‹è¯•"""
    print("=" * 80)
    print("æµ‹è¯•6: æ€§èƒ½æµ‹è¯•")
    print("=" * 80)

    import time

    enhancer = HPORewardEnhancer(total_steps=45000)

    # æµ‹è¯•æƒé‡è·å–æ€§èƒ½
    print("\næµ‹è¯•æƒé‡è·å–æ€§èƒ½ (10000æ¬¡)...")
    start = time.time()
    for _ in range(10000):
        weights = enhancer.get_reward_weights()
    elapsed = time.time() - start

    print(f"  æ€»è€—æ—¶: {elapsed:.3f}s")
    print(f"  å¹³å‡: {elapsed/10000*1000:.4f}ms")

    # æµ‹è¯•å®Œæ•´æ›´æ–°æ€§èƒ½
    print("\næµ‹è¯•å®Œæ•´æ›´æ–°æ€§èƒ½ (10000æ¬¡)...")
    start = time.time()
    for _ in range(10000):
        enhancer.step()
        enhancer.update_outcome('capture')
        enhancer.compute_distance_progress_reward('e1', 'hunter', 100.0)
    elapsed = time.time() - start

    print(f"  æ€»è€—æ—¶: {elapsed:.3f}s")
    print(f"  å¹³å‡: {elapsed/10000*1000:.4f}ms")
    print(f"  é¢„è®¡å¯¹è®­ç»ƒå½±å“: <1%")

    print("\nâœ… æ€§èƒ½æµ‹è¯•é€šè¿‡!\n")


if __name__ == "__main__":
    try:
        test_adaptive_scaling()
        test_adversarial_balancer()
        test_distance_tracker()
        test_hpo_enhancer()
        test_reward_functions()
        test_performance()

        print("=" * 80)
        print("ğŸ‰ æ‰€æœ‰HPOé›†æˆæµ‹è¯•é€šè¿‡!")
        print("=" * 80)
        print("\nHPOæ¨¡å—åŠŸèƒ½éªŒè¯:")
        print("  âœ… è‡ªé€‚åº”æƒé‡ç¼©æ”¾")
        print("  âœ… å¯¹æŠ—å¹³è¡¡æœºåˆ¶")
        print("  âœ… è·ç¦»è¿›åº¦è¿½è¸ª")
        print("  âœ… ç»Ÿä¸€å¢å¼ºå™¨æ¥å£")
        print("  âœ… å¥–åŠ±å‡½æ•°é›†æˆ")
        print("  âœ… æ€§èƒ½å½±å“å¯æ¥å— (<1%)")
        print("\nä¸‹ä¸€æ­¥:")
        print("  1. è¿è¡Œå®é™…è®­ç»ƒæµ‹è¯•")
        print("  2. å¯¹æ¯”åŸºçº¿æ€§èƒ½")
        print("  3. è°ƒä¼˜è¶…å‚æ•°")
        print()

    except AssertionError as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
